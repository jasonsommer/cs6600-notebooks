{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12: Reinforcement learning (RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mylib as my"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reinforcement learning** is about making decisions based on experience. Here we have an agent that is trying to navigate an environment it does not know about. This agent can either fully or partially observe (see or sense) the environment. The agent's interaction with the environment is guided by the rewards (or punishments) it receives from the environment indicating wither it did good (or bad) at the end of the an episode. These rewards are the \"reinforcement\" in reinforcement learning (RL).\n",
    "\n",
    "A common approach to navigating fully observable environments is the so-called **Markov Decision Process (MPD)** which will be the focus of this notebook. MDP is a stochastic process maintaining the Markov property. According to Wikipedia, \"a stochastic process has the Markov property if the conditional probability distribution of future states of the process depends only upon the present state, not on the sequence of events that preceded it.\"\n",
    "\n",
    "Because environments (states, transitions, and rewards) are different from one problem to another, MDP problems can look more different than they actually are.\n",
    "\n",
    "We'll start with example MDP using the stochastic grid environment from the \"Artificial Intelligence: A Modern Approach, 4th edition\" book, which looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img style=\"-webkit-user-select:none; display:block; margin:auto; padding:env(safe-area-inset-top) env(safe-area-inset-right) env(safe-area-inset-bottom) env(safe-area-inset-left);\" src=\"data:image/png;base64,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\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of each cell as a state. For example, the state `(1, 1)` is the start state. Each state has four possible actions: `<` (left),`^` (up), `>` (right), and `v` (down). Every one of these actions has a direction that takes the agent to a new state with 80% probability and to the states at the right angle sides of that direction with 10% probability each side. For example, if the agent is at state `(3, 1)`, then an `^` (up) action takes it to state `(3, 2)` with 80% probability, to state `(2, 1)` with 10% probability, and to state `(4, 1)` with 10% probability. A collision with the wall or with a blocked cell results in no movement.\n",
    "\n",
    "The grid has one blocked cell at `(2, 2)` that the agent cannot get to. There are also two terminal states: a winning state `(4, 3)` with `+1` reward and a losing state `(4, 2)` with a `-1` punishment (negative reward). The process ends when the agent gets into either of these states.\n",
    "\n",
    "Here is a class that represents this environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class GridWorldMDP:\n",
    "  def __init__(self, nCols, nRows, reward, blocked, probs, terminals):\n",
    "    self.nCols = nCols\n",
    "    self.nRows = nRows\n",
    "    self.probs = {\n",
    "      '<': {'v': probs['lhs'], '<': probs['forward'], '^': probs['rhs']}, \n",
    "      '^': {'<': probs['lhs'], '^': probs['forward'], '>': probs['rhs']}, \n",
    "      '>': {'^': probs['lhs'], '>': probs['forward'], 'v': probs['rhs']}, \n",
    "      'v': {'>': probs['lhs'], 'v': probs['forward'], '<': probs['rhs']}\n",
    "    }\n",
    "    self.blocked = blocked \n",
    "    self.terminals = terminals\n",
    "    self.grid_ = {}\n",
    "    self.rewards_ = {}\n",
    "\n",
    "    self.__construct(reward)\n",
    "\n",
    "  def __take_a_step(self, state, action):\n",
    "    \"\"\"\n",
    "    a private method used in building the grid. This is where the destination\n",
    "    of every action along its intented and at right angles directions are \n",
    "    specified.\n",
    "    \"\"\"\n",
    "    col, row = state\n",
    "    if state in self.blocked or state in self.terminals:\n",
    "      to = state\n",
    "    else: \n",
    "      if action == '^':\n",
    "        u = -1 if row == self.nRows else row + 1\n",
    "        to = (col, row if u == -1 else u)\n",
    "      elif action == '<':\n",
    "        l = -1 if col == 1 else col - 1\n",
    "        to = (col if l == -1 else l, row)\n",
    "      elif action == '>':\n",
    "        r = -1 if col == self.nCols else col + 1\n",
    "        to = (col if r == -1 else r, row)\n",
    "      elif action == 'v':\n",
    "        d = -1 if row == 1 else row - 1\n",
    "        to = (col, row if d == -1 else d)\n",
    "\n",
    "    if to in self.blocked:\n",
    "      to = state\n",
    "\n",
    "    rwd = self.rewards_[state]\n",
    "    if to == state:\n",
    "      rwd = 0.0\n",
    "\n",
    "    if to in self.terminals:\n",
    "      rwd = self.terminals[to]\n",
    "    \n",
    "    return to, rwd\n",
    "\n",
    "  def __construct(self, reward):\n",
    "    \"\"\"\n",
    "    a private method that builds the grid.\n",
    "    \"\"\"\n",
    "    for i in range(self.nRows):\n",
    "      for j in range(self.nCols):\n",
    "        s =  (j + 1, self.nRows - i)\n",
    "        blocked_or_terminal = s in self.terminals or s in self.blocked\n",
    "        self.rewards_[s] = reward\n",
    "        if s in self.blocked: self.rewards_[s] = -np.Inf\n",
    "        if s in self.terminals: self.rewards_[s] = self.terminals[s]\n",
    "        self.grid_[s] = {\n",
    "          a: { \n",
    "            b: (*self.__take_a_step(s, b), (.0 if blocked_or_terminal else prob))  for b, prob in a_probs.items() \n",
    "           } for a, a_probs in self.probs.items()\n",
    "        }\n",
    "\n",
    "  def P(self, s, a, s_ = None):\n",
    "    \"\"\"\n",
    "    returns the propbability of going from  state s to state s_ via action a.\n",
    "    \"\"\"\n",
    "    a_probs = list(self.grid_[s][a].values())\n",
    "    if s_ is None:\n",
    "      return a_probs\n",
    "\n",
    "    return sum([x[2] for x in a_probs if x[0] == s_])\n",
    "\n",
    "  def R(self, s, a = None, s_ = None):\n",
    "    \"\"\"\n",
    "    returns the reward of going from  state s to state s_ via action a.\n",
    "    \"\"\"\n",
    "    if a is None or s_ is None:\n",
    "      return self.rewards_[s]\n",
    "\n",
    "    a_probs = list(self.grid_[s][a].values())\n",
    "    return sum([x[1] for x in a_probs if x[0] == s_])\n",
    "\n",
    "  def possible_actions(self):\n",
    "        return list(self.grid_[(1, 1)].keys())\n",
    "    \n",
    "  def print_transitions(self):\n",
    "    out = \"\"\n",
    "    for s, s_actions in self.grid_.items():\n",
    "      if s in self.blocked or s in self.terminals: continue\n",
    "      out += f\"{s}-\"\n",
    "      for a_, s_ in s_actions.items():\n",
    "        out += f\"\\t{a_} :  {'; '.join(str(v) for v in s_.values())}\\n\"\n",
    "\n",
    "    print(out)\n",
    "\n",
    "  def print_in_grid(self, data):\n",
    "    out = \"---------------------------------------\"\n",
    "    for i in range(self.nRows):\n",
    "      out += f\"\\n{(self.nRows - i):>2} |\"\n",
    "      for j in range(self.nCols):\n",
    "        col, row =  j + 1, self.nRows - i\n",
    "        if (col, row) in self.blocked:\n",
    "          value = ' '\n",
    "        elif (col, row) in self.terminals:\n",
    "          value = str(self.rewards_[(col, row)])\n",
    "        else:\n",
    "          value = data[(col, row)]\n",
    "        if isinstance(value, float):\n",
    "          out += f\"{value:>8.2f}\"\n",
    "        else:\n",
    "          out += f\"{value:>8}\"\n",
    "        \n",
    "    print(out)\n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"    \" + \"\".join([f\"{(j + 1): 8}\" for j in range(self.nCols)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class takes multiple parameters describing the environment including:\n",
    "\n",
    "* the rewards the agent gets when he gets into a state.\n",
    "* the probabilities of moving through the grid\n",
    "* the blocked and terminal states.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw = GridWorldMDP(4, 3,\n",
    "  reward= -0.04,\n",
    "  probs= {\"forward\": .8, \"lhs\": .1, \"rhs\": .1},\n",
    "  blocked= [ (2,2) ],\n",
    "  terminals= {(4, 2): -1, (4, 3): +1 }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the reward system of this world:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      " 3 |   -0.04   -0.04   -0.04       1\n",
      " 2 |   -0.04           -0.04      -1\n",
      " 1 |   -0.04   -0.04   -0.04   -0.04\n",
      "---------------------------------------\n",
      "           1       2       3       4\n"
     ]
    }
   ],
   "source": [
    "gw.print_in_grid(gw.rewards_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is also a printout of its transition model. Notice how the blocked and terminal states are not included in this printout, because blocked states are not actual states, and once you are in a terminal state, game is over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)-\t< :  ((1, 2), -0.04, 0.1); ((1, 3), 0.0, 0.8); ((1, 3), 0.0, 0.1)\n",
      "\t^ :  ((1, 3), 0.0, 0.1); ((1, 3), 0.0, 0.8); ((2, 3), -0.04, 0.1)\n",
      "\t> :  ((1, 3), 0.0, 0.1); ((2, 3), -0.04, 0.8); ((1, 2), -0.04, 0.1)\n",
      "\tv :  ((2, 3), -0.04, 0.1); ((1, 2), -0.04, 0.8); ((1, 3), 0.0, 0.1)\n",
      "(2, 3)-\t< :  ((2, 3), 0.0, 0.1); ((1, 3), -0.04, 0.8); ((2, 3), 0.0, 0.1)\n",
      "\t^ :  ((1, 3), -0.04, 0.1); ((2, 3), 0.0, 0.8); ((3, 3), -0.04, 0.1)\n",
      "\t> :  ((2, 3), 0.0, 0.1); ((3, 3), -0.04, 0.8); ((2, 3), 0.0, 0.1)\n",
      "\tv :  ((3, 3), -0.04, 0.1); ((2, 3), 0.0, 0.8); ((1, 3), -0.04, 0.1)\n",
      "(3, 3)-\t< :  ((3, 2), -0.04, 0.1); ((2, 3), -0.04, 0.8); ((3, 3), 0.0, 0.1)\n",
      "\t^ :  ((2, 3), -0.04, 0.1); ((3, 3), 0.0, 0.8); ((4, 3), 1, 0.1)\n",
      "\t> :  ((3, 3), 0.0, 0.1); ((4, 3), 1, 0.8); ((3, 2), -0.04, 0.1)\n",
      "\tv :  ((4, 3), 1, 0.1); ((3, 2), -0.04, 0.8); ((2, 3), -0.04, 0.1)\n",
      "(1, 2)-\t< :  ((1, 1), -0.04, 0.1); ((1, 2), 0.0, 0.8); ((1, 3), -0.04, 0.1)\n",
      "\t^ :  ((1, 2), 0.0, 0.1); ((1, 3), -0.04, 0.8); ((1, 2), 0.0, 0.1)\n",
      "\t> :  ((1, 3), -0.04, 0.1); ((1, 2), 0.0, 0.8); ((1, 1), -0.04, 0.1)\n",
      "\tv :  ((1, 2), 0.0, 0.1); ((1, 1), -0.04, 0.8); ((1, 2), 0.0, 0.1)\n",
      "(3, 2)-\t< :  ((3, 1), -0.04, 0.1); ((3, 2), 0.0, 0.8); ((3, 3), -0.04, 0.1)\n",
      "\t^ :  ((3, 2), 0.0, 0.1); ((3, 3), -0.04, 0.8); ((4, 2), -1, 0.1)\n",
      "\t> :  ((3, 3), -0.04, 0.1); ((4, 2), -1, 0.8); ((3, 1), -0.04, 0.1)\n",
      "\tv :  ((4, 2), -1, 0.1); ((3, 1), -0.04, 0.8); ((3, 2), 0.0, 0.1)\n",
      "(1, 1)-\t< :  ((1, 1), 0.0, 0.1); ((1, 1), 0.0, 0.8); ((1, 2), -0.04, 0.1)\n",
      "\t^ :  ((1, 1), 0.0, 0.1); ((1, 2), -0.04, 0.8); ((2, 1), -0.04, 0.1)\n",
      "\t> :  ((1, 2), -0.04, 0.1); ((2, 1), -0.04, 0.8); ((1, 1), 0.0, 0.1)\n",
      "\tv :  ((2, 1), -0.04, 0.1); ((1, 1), 0.0, 0.8); ((1, 1), 0.0, 0.1)\n",
      "(2, 1)-\t< :  ((2, 1), 0.0, 0.1); ((1, 1), -0.04, 0.8); ((2, 1), 0.0, 0.1)\n",
      "\t^ :  ((1, 1), -0.04, 0.1); ((2, 1), 0.0, 0.8); ((3, 1), -0.04, 0.1)\n",
      "\t> :  ((2, 1), 0.0, 0.1); ((3, 1), -0.04, 0.8); ((2, 1), 0.0, 0.1)\n",
      "\tv :  ((3, 1), -0.04, 0.1); ((2, 1), 0.0, 0.8); ((1, 1), -0.04, 0.1)\n",
      "(3, 1)-\t< :  ((3, 1), 0.0, 0.1); ((2, 1), -0.04, 0.8); ((3, 2), -0.04, 0.1)\n",
      "\t^ :  ((2, 1), -0.04, 0.1); ((3, 2), -0.04, 0.8); ((4, 1), -0.04, 0.1)\n",
      "\t> :  ((3, 2), -0.04, 0.1); ((4, 1), -0.04, 0.8); ((3, 1), 0.0, 0.1)\n",
      "\tv :  ((4, 1), -0.04, 0.1); ((3, 1), 0.0, 0.8); ((2, 1), -0.04, 0.1)\n",
      "(4, 1)-\t< :  ((4, 1), 0.0, 0.1); ((3, 1), -0.04, 0.8); ((4, 2), -1, 0.1)\n",
      "\t^ :  ((3, 1), -0.04, 0.1); ((4, 2), -1, 0.8); ((4, 1), 0.0, 0.1)\n",
      "\t> :  ((4, 2), -1, 0.1); ((4, 1), 0.0, 0.8); ((4, 1), 0.0, 0.1)\n",
      "\tv :  ((4, 1), 0.0, 0.1); ((4, 1), 0.0, 0.8); ((3, 1), -0.04, 0.1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gw.print_transitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MDP algorithms\n",
    "We now look at three algorithms that find optimal policies for this MDP environment. A policy is simply a mapping between states and action. An optimal policy $\\pi^*$ is one that leads to maximum reward.\n",
    "\n",
    "### Value iteration\n",
    "This algorithm assigns each state a utility value that reflects the expected reward for the next action plus the discounted utility of the next state, assuming that the agent chooses the optimal action. The value of a state is defined as:\n",
    "\n",
    "$$V(s) = max_{a} \\Sigma_{s'} P(s, a, s') [R(s, a, s') + \\gamma V(s')]$$\n",
    "\n",
    "where:\n",
    "* $P(s, a, s')$ is the transition probability from state $s$ to state $s'$ using action $a$. \n",
    "* $R(s, a, s')$ is the reward that the agent takes the action $a$ to go from state $s$ to state $s'$.\n",
    "* $\\gamma$ is the discount factor.\n",
    "\n",
    "We can also define what is known as the **Q-function** $Q(s, a)$ which is the expected utility of taking action $a$ in state $s$. That is:\n",
    "\n",
    "$$ Q(s, a) = \\Sigma_{s'} P(s, a, s') [R(s, a, s') + \\gamma V(s')]$s\n",
    "\n",
    "Combining both of the above equations we get:\n",
    "\n",
    "$$V(s) = max_{a} Q(s, a) $$\n",
    "\n",
    "Here is a simple implementation of this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_function(mdp, s, a, V, gamma):\n",
    "  S_a = list(mdp.grid_[s][a].values())\n",
    "  return sum([p * (r + gamma * V[s_]) for (s_, r, p) in S_a])\n",
    "\n",
    "def value_iteration(mdp, n_iter=50, epsilon=.001, gamma = 0.9):\n",
    "  V_= { s : 0.0 for s, _ in mdp.grid_.items()}\n",
    "\n",
    "  for _ in range(n_iter):\n",
    "    V = V_.copy()\n",
    "    for s, A_s in mdp.grid_.items():\n",
    "      V_[s] = max([\n",
    "        q_function(mdp, s, a, V, gamma) for a, _ in A_s.items()\n",
    "      ])\n",
    "       \n",
    "  return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call this function and print $V(s)$ for every state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      " 3 |    0.63    0.78    0.93       1\n",
      " 2 |    0.51            0.59      -1\n",
      " 1 |    0.40    0.34    0.44    0.20\n",
      "---------------------------------------\n",
      "           1       2       3       4\n"
     ]
    }
   ],
   "source": [
    "gw.print_in_grid(value_iteration(gw, n_iter=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "To see what action should be taken at every state, we need to calculate the Q-function using the output of the previous `value_iteration` function. This is the optimal policy $\\pi^*$ which is defined as:\n",
    "\n",
    "$$\\pi^*(s) = argmax_a\\ Q(s, a)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      " 3 |       >       >       >       1\n",
      " 2 |       ^               ^      -1\n",
      " 1 |       ^       >       ^       <\n",
      "---------------------------------------\n",
      "           1       2       3       4\n"
     ]
    }
   ],
   "source": [
    "Q = {} \n",
    "V = value_iteration(gw)\n",
    "for s, A_s in gw.grid_.items():\n",
    "  Q[s] = {}\n",
    "  for a, S_a in A_s.items():\n",
    "    Q[s][a] = q_function(gw, s, a, V, .9) \n",
    "\n",
    "gw.print_in_grid({ s: pd.Series(Q_a).idxmax() for s, Q_a in Q.items() })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-value iteration\n",
    "The above `value_iteration` function gives us $V(s)$ values which are converted to Q-function values to get the optimal policy. We use the algorithm below to calculate q-function values directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_itreration(mdp, n_iter = 50, gamma=0.9):\n",
    "    Q = {}\n",
    "    for s, A_s in mdp.grid_.items():\n",
    "        Q[s] = {}\n",
    "        for a, S_a in A_s.items():\n",
    "            Q[s][a] = 0.0  \n",
    "            \n",
    "    for _ in range(n_iter):\n",
    "        q_prev = Q.copy()\n",
    "        for s, A_s in mdp.grid_.items():\n",
    "            for a, S_a in A_s.items():\n",
    "                Q[s][a] = np.sum([\n",
    "                    p * (mdp.R(s, a, s_) + gamma * max(q_prev[s_].values())) for _, (s_, r, p) in S_a.items() \n",
    "                ])\n",
    "    \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      " 3 |       >       >       >       1\n",
      " 2 |       ^               ^      -1\n",
      " 1 |       ^       >       ^       <\n",
      "---------------------------------------\n",
      "           1       2       3       4\n"
     ]
    }
   ],
   "source": [
    "Q = q_itreration(gw,n_iter=100)\n",
    "gw.print_in_grid({ s: pd.Series(Q_a).idxmax() for s, Q_a in Q.items() })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning\n",
    "Q-learning is used when the agent does not know much about the environment, its rewards, and its transition model. Here we use dynamic programming to construct a table (more like a nested dictionary) called q-table that contains the Q-functions $Q(s, a)$, which reflects the quality of taking action $a$ in state $s$. \n",
    "\n",
    "To update $Q$ we use the update equation:\n",
    "\n",
    "$$Q(s, a) = (1 - \\eta) Q(s, a) + \\eta (r + \\gamma \\max_{a'} Q(s', a'))$$\n",
    "\n",
    "where $\\eta$ is the learning rate, $\\gamma$ is the discount factor, and $r$ is the reward of action $a$ at state $s$. \n",
    "\n",
    "To implement Q-learning for this problem, we define a function that explores this environment by randomly taking one of the possible actions given a state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def explore(mdp, s):\n",
    "    return np.random.choice([ a for a, S_a in mdp.grid_[s].items() if S_a[a][0] != s ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to implement the q-learning algorithm we talked about in class. In this function:\n",
    "* We initialize the q-table to small random values.\n",
    "* We then loop for `episodes` iterations. In each iteration, we:\n",
    "    * pick a random non-terminal initial state $s$\n",
    "    * As long as $s$ is not a terminal state (state F):\n",
    "        * pick an action $a$ using the $\\epsilon$-greedy strategy\n",
    "        * get the reward based on state $s$ and action $a$\n",
    "        * update $Q$\n",
    "        \n",
    " Here is a simple implementation of this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def q_learning(mdp, eta=0.7, gamma=0.9, epsilon=0.2, episodes=1000):\n",
    "    # All valid states\n",
    "    states = [s for s, _ in mdp.grid_.items() if s not in mdp.blocked]\n",
    "\n",
    "    # Initialize the q-table to small random values\n",
    "    Q = {}\n",
    "    for s in states:\n",
    "        Q[s] = {}\n",
    "        for a, S_a in mdp.grid_[s].items():\n",
    "            if S_a[a][0] != s or s in mdp.terminals:\n",
    "                Q[s][a] = np.random.rand() * 0.1 - 0.05\n",
    "                \n",
    "    for _ in range(episodes):\n",
    "        # Pick a non-terminal initial state\n",
    "        while True:\n",
    "            s = states[np.random.randint(len(states))]\n",
    "            if s not in mdp.terminals: break \n",
    "        # Stop at the terminal state\n",
    "        while s not in mdp.terminals:\n",
    "            # epsilon-greedy\n",
    "            if (np.random.rand() < epsilon):\n",
    "                #print(s)\n",
    "                a = explore(mdp, s)\n",
    "            else:\n",
    "                a = pd.Series(Q[s]).idxmax()\n",
    "\n",
    "            s_ = mdp.grid_[s][a][a][0]\n",
    "            r = mdp.R(s,a, s_)                 \n",
    "\n",
    "            # The update rule\n",
    "            Q[s][a] += eta * (r + gamma * max(Q[s_].values()) - Q[s][a])\n",
    "            s = s_\n",
    "\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run this algorithm and print out the returned policies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      " 3 |       >       >       >       1\n",
      " 2 |       ^               ^      -1\n",
      " 1 |       ^       >       ^       <\n",
      "---------------------------------------\n",
      "           1       2       3       4\n"
     ]
    }
   ],
   "source": [
    "Q = q_learning(gw, episodes=1000)\n",
    "gw.print_in_grid({ s: pd.Series(Q_a).idxmax() for s, Q_a in Q.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARSA\n",
    "\n",
    "Another slightly different algorithm is called SARSA which stands for State, Action, Reward, next State, next Action. This algorithm starts in the same way as the above q-learning function; it initializes the q-table. It then loops for `episodes` iterations. In each iteration, it:\n",
    "* picks a random non-terminal initial state $s$\n",
    "* picks an action $a$ from state $s$ using the $\\epsilon$-greedy strategy\n",
    "* As long as $s$ is not a terminal state (state F):\n",
    "    * get the new state $s\\_$ that results from taking action $a$ from state $s$ \n",
    "    * pick a new action $a\\_$ from state $s\\_$ using the $\\epsilon$-greedy strategy\n",
    "    * get the reward based on state $s\\_$ and action $a\\_$\n",
    "    * update $Q$\n",
    "        \n",
    "Here is an implementation of this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarsa(mdp, eta=0.7, gamma=0.9, epsilon=0.3, episodes=1000):\n",
    "    # All valid states\n",
    "    states = [s for s, _ in mdp.grid_.items() if s not in mdp.blocked]\n",
    "\n",
    "    # Initialize the q-table to small random values\n",
    "    Q = {}\n",
    "    for s in states:\n",
    "        Q[s] = {}\n",
    "        for a, S_a in mdp.grid_[s].items():\n",
    "            if S_a[a][0] != s or s in mdp.terminals:\n",
    "                Q[s][a] = np.random.rand() * 0.1 - 0.05\n",
    "                \n",
    "    for _ in range(episodes):\n",
    "        # Pick a non-terminal initial state\n",
    "        while True:\n",
    "            s = states[np.random.randint(len(states))]\n",
    "            if s not in mdp.terminals: break \n",
    "\n",
    "        if (np.random.rand() < epsilon):\n",
    "            a = explore(mdp, s)\n",
    "        else:\n",
    "            a = pd.Series(Q[s]).idxmax()\n",
    "\n",
    "        # Stop at the terminal state\n",
    "        while s not in mdp.terminals:\n",
    "            s_ = mdp.grid_[s][a][a][0]\n",
    "            r = mdp.R(s,a, s_)\n",
    "\n",
    "            # epsilon-greedy\n",
    "            if (np.random.rand() < epsilon):  \n",
    "                if s_ in gw.terminals: # Avoid exploring an empty action list if s_ is terminal\n",
    "                    actions = gw.possible_actions()\n",
    "                    a_ = actions[np.random.randint(len(actions))]\n",
    "                else:\n",
    "                    a_ = explore(mdp, s_)\n",
    "            else:\n",
    "                a_ = pd.Series(Q[s_]).idxmax()\n",
    "\n",
    "            Q[s][a] += eta * (r + gamma * Q[s_][a_] - Q[s][a])\n",
    "            s = s_\n",
    "            a = a_\n",
    "\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run this algorithm and print out the returned policies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      " 3 |       >       >       >       1\n",
      " 2 |       ^               ^      -1\n",
      " 1 |       ^       <       ^       <\n",
      "---------------------------------------\n",
      "           1       2       3       4\n"
     ]
    }
   ],
   "source": [
    "Q = sarsa(gw, episodes=1000)\n",
    "gw.print_in_grid({ s: pd.Series(Q_a).idxmax() for s, Q_a in Q.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another MDP example\n",
    "\n",
    "Here have a simple graph from the textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"60%\" src=\"data:image/svg+xml,%0A%3Csvg version='1.1' viewBox='0.0 0.0 742.2467191601049 334.01049868766404' fill='none' stroke='none' stroke-linecap='square' stroke-miterlimit='10' xmlns:xlink='http://www.w3.org/1999/xlink' xmlns='http://www.w3.org/2000/svg'%3E%3CclipPath id='p.0'%3E%3Cpath d='m0 0l742.2467 0l0 334.0105l-742.2467 0l0 -334.0105z' clip-rule='nonzero'/%3E%3C/clipPath%3E%3Cg clip-path='url(%23p.0)'%3E%3Cpath fill='%23000000' fill-opacity='0.0' d='m0 0l742.2467 0l0 334.0105l-742.2467 0z' fill-rule='evenodd'/%3E%3Cpath fill='%23000000' fill-opacity='0.0' d='m634.3027 54.82498l0 0c0 -28.570951 23.161316 -51.732285 51.7323 -51.732285l0 0c13.720215 0 26.87854 5.4503503 36.5802 15.152035c9.701721 9.701685 15.152039 22.859993 15.152039 36.58025l0 0c0 28.570953 -23.161316 51.732285 -51.73224 51.732285l0 0c-28.570984 0 -51.7323 -23.161331 -51.7323 -51.732285z' fill-rule='evenodd'/%3E%3Cpath stroke='%23000000' stroke-width='1.0' stroke-linejoin='round' stroke-linecap='butt' d='m634.3027 54.82498l0 0c0 -28.570951 23.161316 -51.732285 51.7323 -51.732285l0 0c13.720215 0 26.87854 5.4503503 36.5802 15.152035c9.701721 9.701685 15.152039 22.859993 15.152039 36.58025l0 0c0 28.570953 -23.161316 51.732285 -51.73224 51.732285l0 0c-28.570984 0 -51.7323 -23.161331 -51.7323 -51.732285z' fill-rule='evenodd'/%3E%3Cpath fill='%23000000' d='m681.2819 61.744976l0 -13.359375l9.65625 0l0 1.578125l-7.875 0l0 4.09375l7.375 0l0 1.5625l-7.375 0l0 4.546875l8.1875 0l0 1.578125l-9.96875 0z' fill-rule='nonzero'/%3E%3Cpath fill='%23000000' fill-opacity='0.0' d='m408.2318 179.2633l0 0c0 -28.570953 23.161316 -51.732285 51.73227 -51.732285l0 0c13.720276 0 26.87857 5.450348 36.58026 15.152039c9.701691 9.701675 15.152039 22.859985 15.152039 36.580246l0 0c0 28.570953 -23.161346 51.732285 -51.7323 51.732285l0 0c-28.570953 0 -51.73227 -23.161331 -51.73227 -51.732285z' fill-rule='evenodd'/%3E%3Cpath stroke='%23000000' stroke-width='1.0' stroke-linejoin='round' stroke-linecap='butt' d='m408.2318 179.2633l0 0c0 -28.570953 23.161316 -51.732285 51.73227 -51.732285l0 0c13.720276 0 26.87857 5.450348 36.58026 15.152039c9.701691 9.701675 15.152039 22.859985 15.152039 36.580246l0 0c0 28.570953 -23.161346 51.732285 -51.7323 51.732285l0 0c-28.570953 0 -51.73227 -23.161331 -51.73227 -51.732285z' fill-rule='evenodd'/%3E%3Cpath fill='%23000000' d='m454.6651 186.1833l0 -13.359375l4.609375 0q1.546875 0 2.375 0.203125q1.140625 0.25 1.953125 0.953125q1.0625 0.890625 1.578125 2.28125q0.53125 1.390625 0.53125 3.171875q0 1.515625 -0.359375 2.703125q-0.359375 1.171875 -0.921875 1.9375q-0.546875 0.765625 -1.203125 1.21875q-0.65625 0.4375 -1.59375 0.671875q-0.9375 0.21875 -2.140625 0.21875l-4.828125 0zm1.765625 -1.578125l2.859375 0q1.3125 0 2.0625 -0.234375q0.75 -0.25 1.203125 -0.703125q0.625 -0.625 0.96875 -1.6875q0.359375 -1.0625 0.359375 -2.578125q0 -2.09375 -0.6875 -3.21875q-0.6875 -1.125 -1.671875 -1.5q-0.703125 -0.28125 -2.28125 -0.28125l-2.8125 0l0 10.203125z' fill-rule='nonzero'/%3E%3Cpath fill='%23000000' fill-opacity='0.0' d='m3.0926976 179.2633l0 0c0 -28.570953 23.161333 -51.732285 51.732285 -51.732285l0 0c13.720253 0 26.878563 5.450348 36.580246 15.152039c9.701691 9.701675 15.152039 22.859985 15.152039 36.580246l0 0c0 28.570953 -23.161331 51.732285 -51.732285 51.732285l0 0c-28.570951 0 -51.732285 -23.161331 -51.732285 -51.732285z' fill-rule='evenodd'/%3E%3Cpath stroke='%23000000' stroke-width='1.0' stroke-linejoin='round' stroke-linecap='butt' d='m3.0926976 179.2633l0 0c0 -28.570953 23.161333 -51.732285 51.732285 -51.732285l0 0c13.720253 0 26.878563 5.450348 36.580246 15.152039c9.701691 9.701675 15.152039 22.859985 15.152039 36.580246l0 0c0 28.570953 -23.161331 51.732285 -51.732285 51.732285l0 0c-28.570951 0 -51.732285 -23.161331 -51.732285 -51.732285z' fill-rule='evenodd'/%3E%3Cpath fill='%23000000' d='m48.571945 186.1833l5.124996 -13.359375l1.90625 0l5.46875 13.359375l-2.015625 0l-1.546875 -4.046875l-5.59375 0l-1.46875 4.046875l-1.8749962 0zm3.8593712 -5.484375l4.53125 0l-1.40625 -3.703125q-0.625 -1.6875 -0.9375 -2.765625q-0.265625 1.28125 -0.71875 2.546875l-1.46875 3.921875z' fill-rule='nonzero'/%3E%3Cpath fill='%23000000' fill-opacity='0.0' d='m195.91946 273.6019l0 0c0 -28.570969 23.161331 -51.7323 51.732285 -51.7323l0 0c13.720261 0 26.878555 5.450348 36.580246 15.152039c9.701691 9.701691 15.152039 22.859985 15.152039 36.58026l0 0c0 28.570923 -23.161316 51.73227 -51.732285 51.73227l0 0c-28.570953 0 -51.732285 -23.161346 -51.732285 -51.73227z' fill-rule='evenodd'/%3E%3Cpath stroke='%23000000' stroke-width='1.0' stroke-linejoin='round' stroke-linecap='butt' d='m195.91946 273.6019l0 0c0 -28.570969 23.161331 -51.7323 51.732285 -51.7323l0 0c13.720261 0 26.878555 5.450348 36.580246 15.152039c9.701691 9.701691 15.152039 22.859985 15.152039 36.58026l0 0c0 28.570923 -23.161316 51.73227 -51.732285 51.73227l0 0c-28.570953 0 -51.732285 -23.161346 -51.732285 -51.73227z' fill-rule='evenodd'/%3E%3Cpath fill='%23000000' d='m251.88403 275.83438l1.765625 0.453125q-0.5625 2.171875 -2.0 3.328125q-1.4375 1.140625 -3.53125 1.140625q-2.15625 0 -3.515625 -0.875q-1.34375 -0.890625 -2.0625 -2.546875q-0.703125 -1.671875 -0.703125 -3.59375q0 -2.078125 0.796875 -3.625q0.796875 -1.5625 2.265625 -2.359375q1.484375 -0.8125 3.25 -0.8125q2.0 0 3.359375 1.015625q1.375 1.015625 1.90625 2.875l-1.734375 0.40625q-0.46875 -1.453125 -1.359375 -2.109375q-0.875 -0.671875 -2.203125 -0.671875q-1.546875 0 -2.578125 0.734375q-1.03125 0.734375 -1.453125 1.984375q-0.421875 1.234375 -0.421875 2.5625q0 1.703125 0.5 2.96875q0.5 1.265625 1.546875 1.90625q1.046875 0.625 2.265625 0.625q1.484375 0 2.515625 -0.859375q1.03125 -0.859375 1.390625 -2.546875z' fill-rule='nonzero'/%3E%3Cpath fill='%23000000' fill-opacity='0.0' d='m195.91946 54.82498l0 0c0 -28.570951 23.161331 -51.732285 51.732285 -51.732285l0 0c13.720261 0 26.878555 5.4503503 36.580246 15.152035c9.701691 9.701685 15.152039 22.859993 15.152039 36.58025l0 0c0 28.570953 -23.161316 51.732285 -51.732285 51.732285l0 0c-28.570953 0 -51.732285 -23.161331 -51.732285 -51.732285z' fill-rule='evenodd'/%3E%3Cpath stroke='%23000000' stroke-width='1.0' stroke-linejoin='round' stroke-linecap='butt' d='m195.91946 54.82498l0 0c0 -28.570951 23.161331 -51.732285 51.732285 -51.732285l0 0c13.720261 0 26.878555 5.4503503 36.580246 15.152035c9.701691 9.701685 15.152039 22.859993 15.152039 36.58025l0 0c0 28.570953 -23.161316 51.732285 -51.732285 51.732285l0 0c-28.570953 0 -51.732285 -23.161331 -51.732285 -51.732285z' fill-rule='evenodd'/%3E%3Cpath fill='%23000000' d='m242.78934 61.744976l0 -13.359375l5.015625 0q1.53125 0 2.453125 0.40625q0.921875 0.40625 1.4375 1.25q0.53125 0.84375 0.53125 1.765625q0 0.859375 -0.46875 1.625q-0.453125 0.75 -1.390625 1.203125q1.203125 0.359375 1.859375 1.21875q0.65625 0.859375 0.65625 2.015625q0 0.9375 -0.40625 1.75q-0.390625 0.796875 -0.984375 1.234375q-0.578125 0.4375 -1.453125 0.671875q-0.875 0.21875 -2.15625 0.21875l-5.09375 0zm1.78125 -7.75l2.875 0q1.1875 0 1.6875 -0.140625q0.671875 -0.203125 1.015625 -0.671875q0.34375 -0.46875 0.34375 -1.171875q0 -0.65625 -0.328125 -1.15625q-0.3125 -0.515625 -0.90625 -0.703125q-0.59375 -0.1875 -2.03125 -0.1875l-2.65625 0l0 4.03125zm0 6.171875l3.3125 0q0.859375 0 1.203125 -0.0625q0.609375 -0.109375 1.015625 -0.359375q0.421875 -0.265625 0.6875 -0.75q0.265625 -0.484375 0.265625 -1.125q0 -0.75 -0.390625 -1.296875q-0.375 -0.546875 -1.0625 -0.765625q-0.671875 -0.234375 -1.953125 -0.234375l-3.078125 0l0 4.59375z' fill-rule='nonzero'/%3E%3Cpath fill='%23d9d9d9' d='m634.3027 273.6019l0 0c0 -28.570969 23.161316 -51.7323 51.7323 -51.7323l0 0c13.720215 0 26.87854 5.450348 36.5802 15.152039c9.701721 9.701691 15.152039 22.859985 15.152039 36.58026l0 0c0 28.570923 -23.161316 51.73227 -51.73224 51.73227l0 0c-28.570984 0 -51.7323 -23.161346 -51.7323 -51.73227z' fill-rule='evenodd'/%3E%3Cpath stroke='%23000000' stroke-width='1.0' stroke-linejoin='round' stroke-linecap='butt' d='m634.3027 273.6019l0 0c0 -28.570969 23.161316 -51.7323 51.7323 -51.7323l0 0c13.720215 0 26.87854 5.450348 36.5802 15.152039c9.701721 9.701691 15.152039 22.859985 15.152039 36.58026l0 0c0 28.570923 -23.161316 51.73227 -51.73224 51.73227l0 0c-28.570984 0 -51.7323 -23.161346 -51.7323 -51.73227z' fill-rule='evenodd'/%3E%3Cpath fill='%23000000' d='m681.8682 280.52188l0 -13.359375l9.015625 0l0 1.578125l-7.25 0l0 4.140625l6.265625 0l0 1.578125l-6.265625 0l0 6.0625l-1.765625 0z' fill-rule='nonzero'/%3E%3Cpath fill='%23000000' fill-opacity='0.0' d='m91.40523 142.68306l104.50394 -87.84253' fill-rule='evenodd'/%3E%3Cpath stroke='%23000000' stroke-width='1.0' stroke-linejoin='round' stroke-linecap='butt' d='m91.40523 142.68306l104.50394 -87.84253' fill-rule='evenodd'/%3E%3Cpath fill='%23000000' fill-opacity='0.0' d='m284.232 237.02164l124.0 -57.76378' fill-rule='evenodd'/%3E%3Cpath stroke='%23000000' stroke-width='1.0' stroke-linejoin='round' stroke-linecap='butt' d='m284.232 237.02164l124.0 -57.76378' fill-rule='evenodd'/%3E%3Cpath fill='%23000000' fill-opacity='0.0' d='m299.38403 54.82498l124.0 87.842514' fill-rule='evenodd'/%3E%3Cpath stroke='%23000000' stroke-width='1.0' stroke-linejoin='round' stroke-linecap='butt' d='m299.38403 54.82498l124.0 87.842514' fill-rule='evenodd'/%3E%3Cpath fill='%23000000' fill-opacity='0.0' d='m496.54434 142.68306l152.91336 -51.275597' fill-rule='evenodd'/%3E%3Cpath stroke='%23000000' stroke-width='1.0' stroke-linejoin='round' stroke-linecap='butt' d='m496.54434 142.68306l152.91336 -51.275597' fill-rule='evenodd'/%3E%3Cpath fill='%23000000' fill-opacity='0.0' d='m299.38403 273.6019l334.92914 0' fill-rule='evenodd'/%3E%3Cpath stroke='%23000000' stroke-width='1.0' stroke-linejoin='round' stroke-linecap='butt' d='m299.38403 273.6019l334.92914 0' fill-rule='evenodd'/%3E%3Cpath fill='%23000000' fill-opacity='0.0' d='m686.035 106.55727l0 115.30708' fill-rule='evenodd'/%3E%3Cpath stroke='%23000000' stroke-width='1.0' stroke-linejoin='round' stroke-linecap='butt' d='m686.035 106.55727l0 115.30708' fill-rule='evenodd'/%3E%3Cpath fill='%23000000' fill-opacity='0.0' d='m247.65175 106.55727l0 115.30708' fill-rule='evenodd'/%3E%3Cpath stroke='%23000000' stroke-width='1.0' stroke-linejoin='round' stroke-linecap='butt' d='m247.65175 106.55727l0 115.30708' fill-rule='evenodd'/%3E%3C/g%3E%3C/svg%3E\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example:\n",
    "* We have six states (A through F) and F is the terminal state.\n",
    "* The reward for staying at the same state is -5 (a punishment) except when you are at F. The reward for moving from a state to a non-terminal state is 0. The reward for getting to a terminal state (F) is 100. \n",
    "* In general, the number of actions at a given state is the same as the number of states. This means we have to option (if the environment allows it of course) to go to every other state or stay where it's at. either staying in the same state or moving to another. We can represent illegal transitions with a `-np.inf` (negative infinity) reward.\n",
    "* The goal is to train an agent to navigate this graph (environment) and get to the terminal state F.\n",
    "\n",
    "### Q-learning\n",
    "We can use Q-learning to do this. In this example, the q-table will be $6 \\times 6$. To update $Q$ we use the update equation (same as above):\n",
    "\n",
    "$$Q(s, a) = (1 - \\eta) Q(s, a) + \\eta (r + \\gamma \\max_{a'} Q(s', a'))$$\n",
    "\n",
    "where $\\eta$ is the learning rate, $\\gamma$ is the discount factor, and $r$ is the reward of action $a$ at state $s$. \n",
    "\n",
    "Let's implement Q-learning for this problem in a step by step manner. First we represent the environment graph using adjacency matrix like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.array([\n",
    "    [1,1,0,0,0,0],\n",
    "    [1,1,1,1,0,0],\n",
    "    [0,1,1,1,0,1],\n",
    "    [0,1,1,1,1,0],\n",
    "    [0,0,0,1,1,1],\n",
    "    [0,0,1,0,1,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the reward matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.array([\n",
    "    [     -5,      0,-np.inf,-np.inf,-np.inf,-np.inf],\n",
    "    [      0,     -5,      0,      0,-np.inf,-np.inf],\n",
    "    [-np.inf,      0,     -5,      0,-np.inf,    100],\n",
    "    [-np.inf,      0,      0,     -5,      0,-np.inf],\n",
    "    [-np.inf,-np.inf,-np.inf,      0,     -5,    100],\n",
    "    [-np.inf,-np.inf,      0,-np.inf,-np.inf,      0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these two matrices, we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of states: 6; No of actions: 6\n"
     ]
    }
   ],
   "source": [
    "states = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "n_states, n_actions = R.shape\n",
    "print(f\"No of states: {n_states}; No of actions: {n_actions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some hyperparameters to initialize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.7\n",
    "gamma = 0.4\n",
    "epsilon = 0.1 # for e-greedy\n",
    "episodes = 1000 # no of iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start the Q-learning algorithms by creating a q-table and initializing it to small random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.random.rand(n_states, n_actions) * 0.1 - 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these values and without learning, here is what we get trying to get from A to F."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path too long...\n",
      "A---inf->C---inf->E---5.0->E---5.0->E---5.0->E---5.0->E---5.0->E\n"
     ]
    }
   ],
   "source": [
    "def print_path(Q, start_at):\n",
    "    path = []\n",
    "    s = start_at\n",
    "    count = 0\n",
    "    while s != 5:\n",
    "        a = np.argmax(Q[s,:])\n",
    "        path.append(states[s])\n",
    "        path.append(f\"--{R[s,a]}->\")\n",
    "        # For this example, new state is the chosen action\n",
    "        s = a\n",
    "        count += 1\n",
    "        if count > len(Q):\n",
    "            print(\"Path too long...\")\n",
    "            break\n",
    "            \n",
    "    path.append(states[s])\n",
    "    print(''.join(path))\n",
    "    \n",
    "print_path(Q, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is not even a valid path. Let's learn then.\n",
    "\n",
    "We now loop for `episodes` iterations. In each iteration, we:\n",
    "* pick a random random state $s$\n",
    "* As long as $s$ is not a terminal state (state F):\n",
    "    * pick an action $a$ using the $\\epsilon$-greedy strategy\n",
    "    * get the reward based on state $s$ and action $a$\n",
    "    * update $Q$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 1000 training episodes.\n"
     ]
    }
   ],
   "source": [
    "for _ in range(episodes):\n",
    "    # Pick initial state\n",
    "    s = np.random.randint(n_states)\n",
    "    \n",
    "    # Stop at the terminal state\n",
    "    while s != 5:\n",
    "        # epsilon-greedy\n",
    "        if (np.random.rand()<epsilon):\n",
    "            indices = np.where(T[s,:]!=0)\n",
    "            pick = np.random.randint(np.shape(indices)[1])\n",
    "            a = indices[0][pick]\n",
    "        else:\n",
    "            a = np.argmax(Q[s,:])\n",
    "\n",
    "        r = R[s,a]\n",
    "        # For this example, new state is the chosen action\n",
    "        s_prime = a\n",
    "\n",
    "        Q[s,a] += eta * (r + gamma * np.max(Q[s_prime,:]) - Q[s,a])\n",
    "        s = s_prime\n",
    "        \n",
    "print(f\"Finished {episodes} training episodes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the q-table (rounded to 2 decimal points) we got from the algorithm below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.  16. -inf -inf  -0.  -0.]\n",
      " [  6.  11.  40.  16.  -0.  -0.]\n",
      " [-inf  16.  35.  16. -inf 100.]\n",
      " [-inf  16.  40.  11.  40.  -0.]\n",
      " [ -0.  -0.   0.  16.  35. 100.]\n",
      " [ -0.   0.   0.   0.  -0.  -0.]]\n"
     ]
    }
   ],
   "source": [
    "print(Q.round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test this we can now use this q-table to navigate the environment. Assume that our starting state is A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A--0.0->B--0.0->C--100.0->F\n"
     ]
    }
   ],
   "source": [
    "print_path(Q, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARSA\n",
    "\n",
    "Let's also implement the SARSA (State, Action, Reward, next State, next Action) algorithm described above. We start by initializing the q-table to random small values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.random.rand(n_states,n_actions) * 0.1 - 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again using this table without learning gives us the following path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path too long...\n",
      "A---inf->E---5.0->E---5.0->E---5.0->E---5.0->E---5.0->E---5.0->E\n"
     ]
    }
   ],
   "source": [
    "print_path(Q, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which also is not a valid path. Now we use the SARSA algorithm to learn how to navigate this graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 1000 training episodes.\n"
     ]
    }
   ],
   "source": [
    "episodes = 1000\n",
    "for _ in range(episodes):\n",
    "    # Pick initial state\n",
    "    s = np.random.randint(n_states)\n",
    "    # Pick action epsilon-greedy\n",
    "    if (np.random.rand() < epsilon):\n",
    "        indices = np.where(T[s,:]!=0)\n",
    "        pick = np.random.randint(np.shape(indices)[1])\n",
    "        a = indices[0][pick]\n",
    "    else:\n",
    "        a = np.argmax(Q[s,:])\n",
    "\n",
    "    # Stop at the terminal state\n",
    "    while s != 5:\n",
    "        r = R[s,a]\n",
    "        # For this example, new state is the chosen action\n",
    "        s_prime = a\n",
    "\n",
    "        # Pick action prime\n",
    "        if (np.random.rand() < epsilon):\n",
    "            indices = np.where(T[s_prime,:]!=0)\n",
    "            pick = np.random.randint(np.shape(indices)[1])\n",
    "            a_prime = indices[0][pick]\n",
    "        else:\n",
    "            a_prime = np.argmax(Q[s_prime,:])\n",
    "\n",
    "        Q[s,a] += eta * (r + gamma * Q[s_prime,a_prime] - Q[s,a])\n",
    "\n",
    "        s = s_prime\n",
    "        a = a_prime\n",
    "        \n",
    "print(f\"Finished {episodes} training episodes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've learned, let print the path from A to F:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A--0.0->B--0.0->C--100.0->F\n"
     ]
    }
   ],
   "source": [
    "print_path(Q, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which algorithm (Q-Learning or SARSA) runs faster?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yet another example: Using Gym\n",
    "The hardest part about working RL is specifying the environment. In the simple examples above, we had to think about how to represent states, actions, and transitions, as you saw in the Grid example, that implementation can quickly get complicated. For more complex problems, this could be too much work. \n",
    "\n",
    "To help with that, there is a package called `gym` from [OpenAI](https://gym.openai.com/) which comes with multiple environments that you can use for RL. To install it, use the command:\n",
    "\n",
    "```\n",
    "conda activate ml\n",
    "conda install -c conda-forge gym\n",
    "```\n",
    "\n",
    "Here we use a simple self driving-cab example. The goal of this cab is to pick up the passenger at one location and drop them off in another. \n",
    "\n",
    "Here is what the environment looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m| : | : |\n",
      "|\u001b[35mY\u001b[0m| : |\u001b[34;1mB\u001b[0m: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"Taxi-v3\").env\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a $5 \\times 5$ grid; Think of it as a parking lot. The cab (the yellow block) can pick up passengers from four locations (R, G, Y, B). The passengers can be in 5 locations (in the cab or in one of the pickup locations). The combination of the grid, pickup, and drop-off locations gives us a state space of $5 \\times 5 \\times 4 \\times 5 = 500$ states. A state is then represented by 4-tuple:\n",
    "* row (0 - 4)\n",
    "* column (0 - 4)\n",
    "* passenger index (0-4): 0-3 for the 4 destinations and 4 for the passenger being inside the cab\n",
    "* destination index (0-3)\n",
    "\n",
    "\n",
    "The action spaces has six possible actions (0-5): south, north, east, west, pickup, and drop-off.\n",
    "\n",
    "The solid `|` represent walls preventing the cap from performing certain actions.\n",
    "\n",
    "We can move the cab to any state by doing something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[42mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state = env.encode(4, 0, 4, 0) # (row, column, passenger index (0-4), destination index (0-3))\n",
    "env.s = state\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with these numbers. Notice that the cab color changes from yellow to green when the passenger is in the cap (passenger index 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | :\u001b[42m_\u001b[0m| : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state = env.encode(3, 2, 4, 0) # (row, column, passenger index (0-4), destination index (0-3))\n",
    "env.s = state\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reward table for can be obtained by `env.P`. For example, the reward at the current environment state is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(1.0, 456, -1, False)],\n",
       " 1: [(1.0, 256, -1, False)],\n",
       " 2: [(1.0, 356, -1, False)],\n",
       " 3: [(1.0, 336, -1, False)],\n",
       " 4: [(1.0, 356, -10, False)],\n",
       " 5: [(1.0, 356, -10, False)]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.P[env.s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rewards are structured as follows `(probability, nextstate, reward, done)` such that:\n",
    "\n",
    "* 0-5 corresponds to the actions (south, north, east, west, pickup, drop-off).\n",
    "* In this environment, probability is always 1.0.\n",
    "* `nextstate` determines where the cab will be if that action is taken.\n",
    "* The rewards are as follows:\n",
    "    * -10 for pickup/drop-off\n",
    "    * 20 for being at the drop-off state with passenger inside\n",
    "    * -1 for all other movements.\n",
    "    \n",
    "Now that we have a better idea of how this environment works, we can start implementing the Q-learning algorithm. \n",
    "\n",
    "We define the q-table and initialize it to small random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.random.rand(env.observation_space.n, env.action_space.n) * 0.1 - 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate how bad these initial values by running 100 episodes and reporting the pickup/drop-off penalties encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalty_per_episode(episodes = 100):\n",
    "    total_itrs, total_penalties = 0, 0\n",
    "\n",
    "    for _ in range(episodes):\n",
    "        s = env.reset()\n",
    "        itr, penalties, r = 0, 0, 0\n",
    "\n",
    "        done = False\n",
    "        while not done:\n",
    "            s, r, done, info = env.step(np.argmax(Q[s,:]))\n",
    "\n",
    "            if r == -10:\n",
    "                penalties += 1\n",
    "\n",
    "            itr += 1\n",
    "            if(itr > len(Q)): # to avoid getting stuck\n",
    "                break\n",
    "\n",
    "        total_penalties += penalties\n",
    "        total_itrs += itr\n",
    "\n",
    "    return total_penalties / episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran 100 episodes\n",
      "Penalty per episode: 285.03\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ran {100} episodes\")\n",
    "print(f\"Penalty per episode: {penalty_per_episode(100)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train the agent using the Q-learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 100000 training episodes.\n"
     ]
    }
   ],
   "source": [
    "eta = 0.1\n",
    "gamma = 0.6\n",
    "epsilon = 0.1\n",
    "episodes = 100000\n",
    "\n",
    "for _ in range(episodes):\n",
    "    s = env.reset()\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        # epsilon-greedy\n",
    "        if (np.random.rand()<epsilon):\n",
    "            a = env.action_space.sample()\n",
    "        else:\n",
    "            a = np.argmax(Q[s, :])\n",
    "            \n",
    "        s_prime, r, done, info = env.step(a) \n",
    "        \n",
    "        Q[s,a] += eta * (r + gamma * np.max(Q[s_prime,:]) - Q[s,a])\n",
    "\n",
    "        s = s_prime\n",
    "        \n",
    "print(f\"Finished {episodes} training episodes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now evaluate the agent by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran 100 episodes\n",
      "Penalty per episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ran {100} episodes\")\n",
    "print(f\"Penalty per episode: {penalty_per_episode(100)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHALLENGE (Optional)\n",
    "Train the above cab agent using the SARSA algorithm. Test your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
